From 9974bf8309e9090446b0df638876c8eb2045eccf Mon Sep 17 00:00:00 2001
From: Sandeep Gopalpet <sandeep.kumar@freescale.com>
Date: Tue, 5 Jan 2010 18:37:47 +0530
Subject: [PATCH] gianfar: Per Queue SKB Recycling

Modified the SKB recycling algorithm to introduce per queue
per cpu recycling queue.

Signed-off-by: Sandeep Gopalpet <sandeep.kumar@freescale.com>
---
 drivers/net/gianfar.c       |   72 +++++++++++++++++++++++-------------------
 drivers/net/gianfar.h       |   12 +++---
 drivers/net/gianfar_sysfs.c |    7 +++-
 3 files changed, 50 insertions(+), 41 deletions(-)

diff --git a/drivers/net/gianfar.c b/drivers/net/gianfar.c
index aa4e221..9c6ed67 100644
--- a/drivers/net/gianfar.c
+++ b/drivers/net/gianfar.c
@@ -170,7 +170,7 @@ u16 gfar_select_queue(struct net_device *dev, struct sk_buff *skb);
 #ifdef CONFIG_GFAR_SKBUFF_RECYCLING
 static unsigned int skbuff_truesize(unsigned int buffer_size);
 static void gfar_skbr_register_truesize(struct gfar_private *priv);
-static int gfar_kfree_skb(struct sk_buff *skb);
+static int gfar_kfree_skb(struct sk_buff *skb, int qindex);
 static void gfar_reset_skb_handler(struct gfar_skb_handler *sh);
 #endif
 
@@ -1460,16 +1460,19 @@ static void free_skb_resources(struct gfar_private *priv)
 {
 	struct gfar_priv_tx_q *tx_queue = NULL;
 	struct gfar_priv_rx_q *rx_queue = NULL;
-	int i;
+	int i, cpu;
 
 #ifdef CONFIG_GFAR_SKBUFF_RECYCLING
-	/* 1: spinlocking of skb_handler is required */
-	gfar_free_recycle_queue(&priv->skb_handler, 1);
-	for_each_possible_cpu(i) {
-		gfar_free_recycle_queue(
-			per_cpu_ptr(priv->local_sh, i), 0);
+	for (i = 0; i < priv->num_rx_queues ; i++) {
+		/* 1: spinlocking of skb_handler is required */
+		gfar_free_recycle_queue(&(priv->rx_queue[i]->skb_handler), 1);
+		for_each_possible_cpu(cpu) {
+			gfar_free_recycle_queue(
+				per_cpu_ptr(priv->rx_queue[i]->local_sh,
+								cpu), 0);
+		}
+		free_percpu(priv->rx_queue[i]->local_sh);
 	}
-	free_percpu(priv->local_sh);
 #endif
 
 	/* Go through all the buffer descriptors and free their data buffers */
@@ -1664,7 +1667,7 @@ int startup_gfar(struct net_device *dev)
 	struct rxbd8 *rxbdp;
 	dma_addr_t addr = 0;
 	unsigned long vaddr;
-	int i, j, k;
+	int i, j, k, cpu;
 	struct gfar_private *priv = netdev_priv(dev);
 	struct gfar_priv_tx_q *tx_queue = NULL;
 	struct gfar_priv_rx_q *rx_queue = NULL;
@@ -1795,17 +1798,6 @@ int startup_gfar(struct net_device *dev)
 		txbdp->status |= TXBD_WRAP;
 	}
 
-#ifdef CONFIG_GFAR_SKBUFF_RECYCLING
-	priv->rx_skbuff_truesize = GFAR_DEFAULT_RECYCLE_TRUESIZE;
-	gfar_reset_skb_handler(&priv->skb_handler);
-	priv->local_sh = alloc_percpu(struct gfar_skb_handler);
-
-	for_each_possible_cpu(i) {
-		gfar_reset_skb_handler(
-				per_cpu_ptr(priv->local_sh, i));
-	}
-#endif
-
 	for (i = 0; i < priv->num_rx_queues; i++) {
 		rx_queue = priv->rx_queue[i];
 		rx_queue->cur_rx = rx_queue->rx_bd_base;
@@ -1837,6 +1829,21 @@ int startup_gfar(struct net_device *dev)
 		rxbdp->status |= RXBD_WRAP;
 	}
 
+#ifdef CONFIG_GFAR_SKBUFF_RECYCLING
+	for (i = 0;  i < priv->num_rx_queues; i++) {
+		priv->rx_queue[i]->rx_skbuff_truesize =
+					GFAR_DEFAULT_RECYCLE_TRUESIZE;
+		gfar_reset_skb_handler(&(priv->rx_queue[i]->skb_handler));
+		priv->rx_queue[i]->local_sh = alloc_percpu(
+						struct gfar_skb_handler);
+
+		for_each_possible_cpu(cpu) {
+			gfar_reset_skb_handler(
+				per_cpu_ptr(priv->rx_queue[i]->local_sh, cpu));
+		}
+	}
+#endif
+
 	for (i = 0; i < priv->num_grps; i++) {
 		err = register_grp_irqs(&priv->gfargrp[i]);
 		if (err) {
@@ -2449,9 +2456,6 @@ static int gfar_change_mtu(struct net_device *dev, int new_mtu)
 
 #ifdef CONFIG_GFAR_SKBUFF_RECYCLING
 	gfar_skbr_register_truesize(priv);
-	printk(KERN_INFO"%s: MTU = %d (frame size=%d, truesize=%d)\n",
-			dev->name, dev->mtu, frame_size,
-			priv->rx_skbuff_truesize);
 #endif /*CONFIG_GFAR_SKBUFF_RECYCLING*/
 
 	gfar_write(&regs->mrblr, priv->rx_buffer_size);
@@ -2568,7 +2572,7 @@ static int gfar_clean_tx_ring(struct gfar_priv_tx_q *tx_queue)
 		}
 
 #ifdef CONFIG_GFAR_SKBUFF_RECYCLING
-		howmany_recycle += gfar_kfree_skb(skb);
+		howmany_recycle += gfar_kfree_skb(skb, tx_queue->qindex);
 #else
 		dev_kfree_skb_any(skb);
 #endif
@@ -2694,7 +2698,11 @@ static unsigned int skbuff_truesize(unsigned int buffer_size)
 
 static void gfar_skbr_register_truesize(struct gfar_private *priv)
 {
-	priv->rx_skbuff_truesize = skbuff_truesize(priv->rx_buffer_size);
+	int i = 0;
+
+	for (i = 0; i < priv->num_rx_queues; i++)
+		priv->rx_queue[i]->rx_skbuff_truesize =
+				skbuff_truesize(priv->rx_buffer_size);
 }
 
 static inline void gfar_clean_reclaim_skb(struct sk_buff *skb)
@@ -2753,9 +2761,8 @@ static inline void gfar_clean_reclaim_skb(struct sk_buff *skb)
 	skb->skb_owner = owner;
 }
 
-static int gfar_kfree_skb(struct sk_buff *skb)
+static int gfar_kfree_skb(struct sk_buff *skb, int qindex)
 {
-	unsigned long int flags;
 	struct gfar_private *priv;
 	struct gfar_skb_handler *sh;
 
@@ -2765,19 +2772,18 @@ static int gfar_kfree_skb(struct sk_buff *skb)
 			goto _normal_free;
 
 	priv = netdev_priv(skb->skb_owner);
-	if (skb->truesize == priv->rx_skbuff_truesize) {
-		sh = &priv->skb_handler;
+	if (skb->truesize == priv->rx_queue[qindex]->rx_skbuff_truesize) {
+		sh = per_cpu_ptr(priv->rx_queue[qindex]->local_sh,
+							smp_processor_id());
 		/* loosly checking */
 		if (likely(sh->recycle_count < sh->recycle_max)) {
 			if (!atomic_dec_and_test(&skb->users))
 				return 0;
 			gfar_clean_reclaim_skb(skb);
 			/* lock sh for add one */
-			spin_lock_irqsave(&sh->lock, flags);
 			skb->next = sh->recycle_queue;
 			sh->recycle_queue = skb;
 			sh->recycle_count++;
-			spin_unlock_irqrestore(&sh->lock, flags);
 			return 1;
 		}
 	}
@@ -2958,7 +2964,7 @@ int gfar_clean_rx_ring(struct gfar_priv_rx_q *rx_queue, int rx_work_limit)
 				priv->padding;
 
 #ifdef CONFIG_GFAR_SKBUFF_RECYCLING
-	local_sh = per_cpu_ptr(priv->local_sh, smp_processor_id());
+	local_sh = per_cpu_ptr(rx_queue->local_sh, smp_processor_id());
 	if (local_sh->recycle_queue) {
 		local_head = local_sh->recycle_queue;
 		free_skb = local_sh->recycle_count;
@@ -2969,7 +2975,7 @@ int gfar_clean_rx_ring(struct gfar_priv_rx_q *rx_queue, int rx_work_limit)
 		free_skb = 0;
 	}
 	/* global skb_handler for this device */
-	sh = &priv->skb_handler;
+	sh = &rx_queue->skb_handler;
 #endif
 
 	while (!((bdp->status & RXBD_EMPTY) || (--rx_work_limit < 0))) {
diff --git a/drivers/net/gianfar.h b/drivers/net/gianfar.h
index 35077cb..1489c9a 100644
--- a/drivers/net/gianfar.h
+++ b/drivers/net/gianfar.h
@@ -1007,7 +1007,7 @@ struct gfar {
 };
 
 #ifdef CONFIG_GFAR_SKBUFF_RECYCLING
-#define GFAR_DEFAULT_RECYCLE_MAX 64
+#define GFAR_DEFAULT_RECYCLE_MAX 32
 #define GFAR_DEFAULT_RECYCLE_TRUESIZE (SKB_DATA_ALIGN(DEFAULT_RX_BUFFER_SIZE \
 		+ RXBUF_ALIGNMENT + NET_SKB_PAD) + sizeof(struct sk_buff))
 
@@ -1146,6 +1146,11 @@ struct gfar_priv_rx_q {
 	/* RX Coalescing values */
 	unsigned char rxcoalescing;
 	unsigned long rxic;
+#ifdef CONFIG_GFAR_SKBUFF_RECYCLING
+	unsigned int rx_skbuff_truesize;
+	struct gfar_skb_handler skb_handler;
+	struct gfar_skb_handler *local_sh; /*per_cpu*/
+#endif
 };
 
 /**
@@ -1226,11 +1231,6 @@ struct gfar_private {
 
 	u32 cur_filer_idx;
 
-#ifdef CONFIG_GFAR_SKBUFF_RECYCLING
-	unsigned int rx_skbuff_truesize;
-	struct gfar_skb_handler skb_handler;
-	struct gfar_skb_handler *local_sh; /*per_cpu*/
-#endif
 	struct vlan_group *vlgrp;
 
 	/* Hash registers and their width */
diff --git a/drivers/net/gianfar_sysfs.c b/drivers/net/gianfar_sysfs.c
index aca00f9..acdc310 100644
--- a/drivers/net/gianfar_sysfs.c
+++ b/drivers/net/gianfar_sysfs.c
@@ -325,7 +325,8 @@ static ssize_t gfar_show_recycle_max(struct device *dev,
 		struct device_attribute *attr, char *buf)
 {
 	struct gfar_private *priv = netdev_priv(to_net_dev(dev));
-	return sprintf(buf, "%d\n", priv->skb_handler.recycle_max);
+	return sprintf(buf, "%d\n",
+		priv->rx_queue[smp_processor_id()]->skb_handler.recycle_max);
 }
 
 static ssize_t gfar_set_recycle_max(struct device *dev,
@@ -334,12 +335,14 @@ static ssize_t gfar_set_recycle_max(struct device *dev,
 {
 	struct gfar_private *priv = netdev_priv(to_net_dev(dev));
 	unsigned int length = simple_strtoul(buf, NULL, 0);
+	int i = 0;
 
 	/* recycling max management is loosely done. If the count is more
 	 * than max, simply don't keep the buffer until the current amount
 	 * lower than max.
 	 */
-	priv->skb_handler.recycle_max = length;
+	for (i = 0; i < priv->num_rx_queues; i++)
+		priv->rx_queue[i]->skb_handler.recycle_max = length;
 	return count;
 }
 
-- 
1.5.2.2

